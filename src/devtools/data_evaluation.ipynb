{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Selection\n",
    "Select `index` value from 0 to 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the index manually if needed\n",
    "index = int(input(\"Enter an index value (0-14): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for PydanticAI to work with Jupyter (nested event loops)\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pastel.classifiers import classify_insurance_image\n",
    "from pastel.parsers import parse_assertion, parse_evidence, check_grammar\n",
    "from pastel.evaluation import consolidate_evaluations\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pandas as pd\n",
    "import logfire\n",
    "import os\n",
    "from pastel.helpers import (\n",
    "    load_images_from_directory,\n",
    "    create_consolidated_image,\n",
    "    export_evaluation_to_markdown,\n",
    ")\n",
    "from pastel.models import (\n",
    "    InsightPlots,\n",
    "    InputModel,\n",
    ")\n",
    "\n",
    "if os.getenv(\"PYDANTIC_LOGFIRE_TOKEN\"):\n",
    "    logfire.configure(token=os.getenv(\"PYDANTIC_LOGFIRE_TOKEN\"))\n",
    "    logfire.instrument_openai()\n",
    "    logfire.instrument_anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insight Validation\n",
    "- Load datasets\n",
    "- Collect images\n",
    "- Parse Insight\n",
    "  - conclusion\n",
    "  - supporting premises\n",
    "- Evaluate premises\n",
    "- Check grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_df = pd.read_excel(\"../data/Insights.xlsx\")\n",
    "\n",
    "input_model = InputModel(\n",
    "    name=insights_df[\"programname\"][index],\n",
    "    insight=insights_df[\"insight\"][index],\n",
    "    line_of_business=insights_df[\"line_of_business\"][index],\n",
    ")\n",
    "\n",
    "assertion = await parse_assertion(input_model)\n",
    "insight = await parse_evidence(assertion)\n",
    "\n",
    "# Retrieve data sets\n",
    "lrs = pd.read_excel(\"../data/lrs.xlsx\")\n",
    "lrs_data = lrs.loc[lrs[\"programname\"] == insight.name].drop(columns=[\"programname\"])\n",
    "\n",
    "images = InsightPlots(plots=load_images_from_directory(f\"../data/{insight.name.replace('/', '-')}\"))\n",
    "consolidated_image = create_consolidated_image(lrs_data, images, insight)\n",
    "premises = await classify_insurance_image(consolidated_image, insight.evidence)\n",
    "grammar = await check_grammar(insight)\n",
    "final_evaluation = await consolidate_evaluations(insight, premises, grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Validation Resuls\n",
    "- Display report\n",
    "- Write markdown to `../reports/` folder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"---\"))\n",
    "display(Markdown(\"# Overall Assessment\\n\\n---\"))\n",
    "display(Markdown(f'#### \"{insight.insight}\"<br>'))\n",
    "display(Markdown(f\"## {final_evaluation.overall_valid}\"))\n",
    "display(Markdown(final_evaluation.reasoning))\n",
    "\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(\"## Conclusion\\n\\n\"))\n",
    "display(Markdown(f'#### \"{insight.conclusion}\"<br><br>'))\n",
    "\n",
    "display(Markdown(f\"---\"))\n",
    "display(Markdown(\"## Premises\\n\\n\"))\n",
    "\n",
    "if not premises:\n",
    "    display(Markdown(\"####No premises found\"))\n",
    "\n",
    "else:\n",
    "    for i, premise in enumerate(premises):\n",
    "        display(Markdown(f\"#### {i+1}. {premise.claim}\"))\n",
    "        display(Markdown(f\"**Status** <br>{premise.status} <br>{premise.confidence} confidence\"))\n",
    "        display(Markdown(f\"**Rationale** <br>{premise.reasoning}<br><br>\"))\n",
    "\n",
    "display(Markdown(f\"---\"))\n",
    "if grammar.errors:\n",
    "    error_list = \"\\n\".join([f\"- {error}\" for error in grammar.errors])\n",
    "    display(Markdown(\"## Grammar\\n\\n\" + error_list))\n",
    "else:\n",
    "    display(Markdown(\"## Grammar\\n\\n\"))\n",
    "    display(Markdown(\"#### No grammatical errors found\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_result = export_evaluation_to_markdown(insight, final_evaluation, premises, grammar)\n",
    "display(Markdown(f\"**{md_result}**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
